{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from transformers import BertModel, DistilBertModel\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import datasets\n",
    "import numpy as np\n",
    "import os.path\n",
    "import data\n",
    "from datasets import load_from_disk\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "from auggam import analyze_helper\n",
    "from auggam import config\n",
    "from os.path import join as oj\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = data.load_fitted_results()\n",
    "# rs.to_pickle(oj(config.results_dir, 'fitted_results_aggregated.pkl'))\n",
    "\n",
    "rs = pd.read_pickle(oj(config.results_dir, 'fitted_results_aggregated.pkl'))\n",
    "rr, r_sem = analyze_helper.average_seeds(rs)\n",
    "rs.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calc accs for tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_checkpoint(checkpoint):\n",
    "        cp = checkpoint.lower()\n",
    "        if '/' in cp or 'finetune' in cp:\n",
    "            if 'distilbert' in cp:\n",
    "                return 'distilbert-finetuned'\n",
    "            elif 'roberta' in cp:\n",
    "                return 'roberta-finetuned'\n",
    "            else:\n",
    "                return 'bert-finetuned'\n",
    "        else:\n",
    "            return checkpoint\n",
    "\n",
    "def get_acc_table(r):\n",
    "    r = r[['dataset', 'checkpoint', 'layer', 'parsing'] + ['acc_val_print']]\n",
    "    r.checkpoint = r.checkpoint.apply(rename_checkpoint)\n",
    "\n",
    "    # group by (dataset, checkpoint, layer)\n",
    "    rg = r.groupby(['dataset', 'checkpoint', 'layer', 'parsing'])\n",
    "\n",
    "    # calc max acc\n",
    "    rg = rg.max()\n",
    "\n",
    "    # make acc table (dataset x [checkpoint, layer])\n",
    "    rg = rg.reset_index().pivot(index='dataset',\n",
    "                                 columns=['checkpoint', 'layer', 'parsing'],\n",
    "                                 values='acc_val_print')\n",
    "    rg.columns = ['___'.join(s) for s in rg.columns.to_flat_index()] # flatten index to tuples\n",
    "    return rg\n",
    "\n",
    "r = rr[rr.subsample == -1]\n",
    "accs = get_acc_table(r)\n",
    "r1 = r[r.ngrams == 1]\n",
    "accs1 = get_acc_table(r1).add_suffix('___ngrams=1')\n",
    "accs = accs.join(accs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs.transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**best-model accs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'bert-finetuned___last_hidden_state_mean___': '\\\\textbf{Emb-GAM}', #'\\\\textbf{Emb-grams (BERT finetuned)}',\n",
    "    'countvectorizer___last_hidden_state_mean___': 'Bag of ngrams',\n",
    "    'tfidfvectorizer___last_hidden_state_mean___': 'TF-IDF',\n",
    "    'bert-finetuned___last_hidden_state_mean______ngrams=1': '\\makecell[l]{Emb-GAM\\\\\\\\(unigrams only)}',    # 'Emb-GAM (Unigrams only)',# '\\makecell{Emb-grams\\\\\\\\(BERT finetuned, Ngram size=1)}',    \n",
    "}\n",
    "\n",
    "tab = accs[list(columns.keys())].rename(columns=columns)\n",
    "tab\n",
    "\n",
    "# rename index\n",
    "tab.index = map(analyze_helper.DSETS_RENAME_DICT.get, tab.index, tab.index)\n",
    "# tab.index = tab.append(tab.pop())\n",
    "# tab.round(2)\n",
    "\n",
    "# tab2 = tab.apply(analyze_helper.bold_extreme_values, axis=1)\n",
    "tab2 = tab\n",
    "print(tab2.transpose().to_latex(escape=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**model variations table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'bert-finetuned___last_hidden_state_mean___': '\\makecell{BERT finetuned}',\n",
    "    'bert-finetuned___pooler_output___': '\\makecell{BERT finetuned\\\\\\\\(pooler output)}',\n",
    "    'bert-finetuned___last_hidden_state_mean___noun_chunks': '\\makecell{BERT finetuned\\\\\\\\(noun chunks)}',    \n",
    "    'bert-base-uncased___last_hidden_state_mean___': 'BERT',\n",
    "    'bert-base-uncased___pooler_output___': '\\makecell{BERT\\\\\\\\(pooler output)}',    \n",
    "    'bert-base-uncased___last_hidden_state_mean___': 'BERT',\n",
    "    'distilbert-base-uncased___last_hidden_state_mean___': 'DistilBERT finetuned',\n",
    "    'distilbert-finetuned___last_hidden_state_mean___': 'DistilBERT',\n",
    "}\n",
    "\n",
    "tab = accs[list(columns.keys())].rename(columns=columns)\n",
    "tab\n",
    "\n",
    "# rename index\n",
    "tab.index = map(analyze_helper.DSETS_RENAME_DICT.get, tab.index, tab.index)\n",
    "tab = tab.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tab.transpose().to_latex(escape=False, column_format='c' + 'l' * (tab.shape[1] - 1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# all curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvu.set_style()\n",
    "plt.figure(figsize=(6, 4.75))\n",
    "plt.rcParams['font.size'] = '14'\n",
    "\n",
    "for i, dset in enumerate(['financial_phrasebank', 'rotten_tomatoes', 'sst2', 'emotion']):\n",
    "    # r = rs[rs.dataset == dset]\n",
    "    r = rr[rr.dataset == dset]    \n",
    "    r = r[r.parsing == '']\n",
    "    r1 = r[~r.checkpoint.str.lower().str.contains('bert')]\n",
    "    # r2 = r[\n",
    "    #     (r.checkpoint.apply(rename_checkpoint) == 'bert-base-uncased') & \\\n",
    "    #     (r.layer == 'last_hidden_state_mean')\n",
    "    # ]\n",
    "    r3 = r[\n",
    "        (r.checkpoint.apply(rename_checkpoint) == 'bert-finetuned') & \\\n",
    "        (r.layer == 'last_hidden_state_mean')\n",
    "    ]    \n",
    "    # r = r1.append(r2).append(r3)\n",
    "    # r = r1.append(r3)\n",
    "    r = pd.concat((r1, r3))\n",
    "\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.title(f'{analyze_helper.DSETS_RENAME_DICT.get(dset).replace(\"Financial phrasebank\", \"FPB\")}', fontsize='large')\n",
    "    d = r[(r.subsample == -1)]\n",
    "\n",
    "    curve = sorted(d.groupby(['checkpoint', 'all', 'norm']),\n",
    "                   key=lambda x: analyze_helper.COLUMNS_RENAME_DICT.get(x[0][0], 'BERT finetuned'))\n",
    "    # curve.append(curve.pop(0)) # move BERT to bottom\n",
    "    for key, group in curve:\n",
    "        g = group.sort_values('ngrams')\n",
    "        if 'distilbert' in key[0].lower():\n",
    "            label = analyze_helper.COLUMNS_RENAME_DICT.get(key[0], 'Emb-GAM (DistilBERT finetuned)')    \n",
    "        else:\n",
    "            label = analyze_helper.COLUMNS_RENAME_DICT.get(key[0], 'Aug-Linear')\n",
    "        if 'Aug-Linear' in label:\n",
    "            # plt.plot(g.ngrams, g.acc_val, '.-', label=label, lw=2.5, color='black', ms=8)\n",
    "            plt.errorbar(g.ngrams, g.acc_val, yerr=g.acc_val_sem, fmt='.-', label=label, lw=2.5, color='C0', ms=8)\n",
    "        else:\n",
    "            if label == 'Bag of ngrams':\n",
    "                color = '#555'\n",
    "            elif label == 'TF-IDF':\n",
    "                color = '#AAA'\n",
    "            # plt.plot(g.ngrams, g.acc_val, '.--', label=label, lw=1.5, alpha=0.8, ms=8)\n",
    "            plt.errorbar(g.ngrams, g.acc_val, yerr=g.acc_val_sem, fmt='.-', label=label, lw=1.5, alpha=0.8, ms=8, color=color)\n",
    "    if i % 2 == 0:\n",
    "        plt.ylabel(f'Accuracy', fontsize='large')\n",
    "    if i >= 2:\n",
    "        plt.xlabel('Ngram size', fontsize='large')\n",
    "    # plt.xlabel('Ngram size', fontsize='large')\n",
    "    # plt.legend()\n",
    "#         dvu.line_legend(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "# plt.legend(bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"expand\", borderaxespad=0, ncol=3)\n",
    "# plt.legend(bbox_to_anchor=(1.04, 1.0), loc=\"center left\",\n",
    "#            borderaxespad=0, labelcolor='linecolor')\n",
    "# plt.legend(bbox_to_anchor=(1.04, 1.0), loc=\"center left\",\n",
    "        #    borderaxespad=0,)\n",
    "plt.legend(fontsize='medium', bbox_to_anchor=(0.5, -0.45))\n",
    "plt.savefig(f'acc_by_ngrams_full.pdf', bbox_inches='tight')\n",
    "#     plt.show()    \n",
    "    #     print(curve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## older versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in ['financial_phrasebank', 'rotten_tomatoes', 'sst2']: # rs.dataset.unique():\n",
    "    r = rs[rs.dataset == dset]\n",
    "\n",
    "    R = 1\n",
    "    C = 3\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    # plt.figure(figsize=(8, 12))\n",
    "    for i, subsample in enumerate([100, 1000, -1]):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.title('Num train=' + str(subsample))\n",
    "        d = r[r.subsample == subsample]\n",
    "\n",
    "        curve = sorted(d.groupby(['checkpoint', 'all', 'norm']),\n",
    "                       key=lambda x: data.COLUMNS_RENAME_DICT.get(x[0][0], 'BERT finetuned'))\n",
    "        curve.append(curve.pop(0)) # move BERT to bottom\n",
    "        for key, group in curve:\n",
    "            g = group.sort_values('ngrams')\n",
    "            label = data.COLUMNS_RENAME_DICT.get(key[0], 'BERT finetuned')\n",
    "            if label == 'BERT finetuned':\n",
    "                plt.plot(g.ngrams, g.acc_val, '.-', label=label, lw=2, color='black')\n",
    "            else:\n",
    "                plt.plot(g.ngrams, g.acc_val, '.-', label=label, lw=1)\n",
    "        plt.ylabel(f'Accuracy ({data.DSETS_RENAME_DICT.get(dset)})')\n",
    "        plt.xlabel('N-gram size')\n",
    "        plt.legend()\n",
    "#         dvu.line_legend(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/acc_by_ngrams_{dset}.pdf')\n",
    "#     plt.show()    \n",
    "    #     print(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i, dset in enumerate(['financial_phrasebank', 'rotten_tomatoes', 'sst2']):\n",
    "    r = rs[rs.dataset == dset]\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.title(f'{data.DSETS_RENAME_DICT.get(dset)}', fontsize='large')\n",
    "    d = r[r.subsample == subsample]\n",
    "\n",
    "    curve = sorted(d.groupby(['checkpoint', 'all', 'norm']),\n",
    "                   key=lambda x: data.COLUMNS_RENAME_DICT.get(x[0][0], 'BERT finetuned'))\n",
    "    curve.append(curve.pop(0)) # move BERT to bottom\n",
    "    for key, group in curve:\n",
    "        g = group.sort_values('ngrams')\n",
    "        label = data.COLUMNS_RENAME_DICT.get(key[0], 'BERT finetuned')\n",
    "        if label == 'BERT finetuned':\n",
    "            plt.plot(g.ngrams, g.acc_val, '.-', label=label, lw=2.5, color='black')\n",
    "        else:\n",
    "            plt.plot(g.ngrams, g.acc_val, '.-', label=label, lw=1.5)\n",
    "    plt.ylabel(f'Accuracy', fontsize='large')\n",
    "    plt.xlabel('Ngram size', fontsize='large')\n",
    "#     plt.legend()\n",
    "#         dvu.line_legend(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "plt.legend(labelcolor='linecolor', fontsize='large')\n",
    "# plt.savefig(f'results/acc_by_ngrams_full.pdf')\n",
    "#     plt.show()    \n",
    "    #     print(curve)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import embgam\n",
    "df = deepcopy(rs)\n",
    "df.checkpoint_clean = df.checkpoint.apply(rename_checkpoint)\n",
    "df = df[(df.checkpoint_clean == 'bert-finetuned') * (df.subsample == -1) * (df['all'] == 'all') * (df['norm'] == '')]\n",
    "idx = df.groupby('dataset')['acc_val'].transform(max) == df['acc_val']\n",
    "df = df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fname(row):\n",
    "    out_dir_name = embgam.data.get_dir_name(\n",
    "        row, seed=row.seed)\n",
    "    save_dir = oj(config.results_dir, row.dataset, out_dir_name)\n",
    "    save_dir += '-all'\n",
    "    results_file = save_dir + '/results.pkl'\n",
    "    out_name = 'results/best___' + os.path.basename(save_dir) + '.pkl'\n",
    "    print('cp', results_file, out_name, '\\n')\n",
    "for i in range(df.shape[0]):\n",
    "    print_fname(df.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
