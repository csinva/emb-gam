{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import BertModel, DistilBertModel\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import datasets\n",
    "import numpy as np\n",
    "import os.path\n",
    "from spacy.lang.en import English\n",
    "from datasets import load_from_disk\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import dvu\n",
    "from typing import List\n",
    "dvu.set_style()\n",
    "import pandas as pd\n",
    "from os.path import join as oj\n",
    "import data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append('../experiments')\n",
    "from auggam import config\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract the relevant model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/.llm/lib/python3.9/site-packages/sklearn/base.py:299: UserWarning: Trying to unpickle estimator LogisticRegressionCV from version 0.24.2 when using version 1.2.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cached_model_fname = oj(config.repo_dir, 'results', 'sst_bert_finetuned_ngrams=2.pkl')\n",
    "row = pkl.load(open(cached_model_fname, \"rb\"))\n",
    "\n",
    "# r = data.load_fitted_results(fname_filters=['bert-base', 'sub=-1'], dset_filters=['sst2'])\n",
    "# row = r[(r.checkpoint == 'textattack/bert-base-uncased-SST-2') & (r.ngrams == 2)].iloc[0]\n",
    "# row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embgam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/bert-base-uncased-SST-2 were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(row.checkpoint) # for actually passing things to the model\n",
    "model = AutoModel.from_pretrained(row.checkpoint)\n",
    "logistic = row.model\n",
    "\n",
    "seqs = ['not bad', 'not', 'very', 'good', 'not very', 'very good', 'not very good']\n",
    "device = 'cpu'\n",
    "tokens = tokenizer(seqs, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(**tokens) # has two keys, 'last_hidden_state', 'pooler_output'\n",
    "embs = output[row.layer].cpu().detach().numpy()\n",
    "# pkl.dump(embs, open('../results/embs_sst_unigram_bigram.pkl', 'wb'))\n",
    "scores = embs @ row.model.coef_.T\n",
    "scores_embgam = {\n",
    "    seqs[i]: scores[i][0]\n",
    "    for i in range(len(seqs))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "pipe = pipeline('text-classification', model=row.checkpoint) #, return_all_scores=True)\n",
    "\n",
    "def pred(x: List) -> np.ndarray:\n",
    "    # print(x)\n",
    "    out = pipe(x)\n",
    "    preds = np.array([d['score'] for d in out]) # for class 1\n",
    "    preds_proba = np.vstack((preds, 1 - preds)).T\n",
    "    # print(len(x), preds_proba.shape)\n",
    "    return preds_proba\n",
    "pred(['very good', 'not bad', 'excellent']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array(['negative', 'positive'])\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance('not very good', pred) #, num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_scores = exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lime = {\n",
    "    exp_scores[i][0]: exp_scores[i][1]\n",
    "    for i in range(len(exp_scores))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# load a transformers pipeline model\n",
    "model = pipeline('text-classification', model=row.checkpoint, return_all_scores=True)\n",
    "\n",
    "# explain the model on two sample inputs\n",
    "explainer = shap.Explainer(model, masker = shap.maskers.Text(tokenizer=r\"\\W+\")) \n",
    "shap_values = explainer([\"not very good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_shap = {\n",
    "    shap_values[0].data[i]: shap_values[0].values[i][1]\n",
    "    for i in range(len(shap_values[0].data))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregate and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_all = {\n",
    "    'embgam': scores_embgam,\n",
    "    'lime': scores_lime,\n",
    "    'shap': scores_shap,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embgam': {'not bad': 0.3501985633960234,\n",
       "  'not': -0.33742450575224603,\n",
       "  'very': -0.04491109966145235,\n",
       "  'good': 0.6257117992942993,\n",
       "  'not very': -1.3865683317300737,\n",
       "  'very good': 0.7019088348007105,\n",
       "  'not very good': -1.3237535853206817},\n",
       " 'lime': {'good': -0.019377856077658535,\n",
       "  'very': -0.018164648371516778,\n",
       "  'not': -0.008505737770279818},\n",
       " 'shap': {'not ': -0.9633358393621165,\n",
       "  'very ': -0.006509928818559274,\n",
       "  'good': 0.02823943691328168}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(scores_all, open(oj(config.results_dir, 'feat_imp_scores_ex.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize so that all scores are between [-1, 1]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embgam': {'not bad': 0.25256495145757973,\n",
       "  'not': -0.24335223734067887,\n",
       "  'very': -0.032390109188066535,\n",
       "  'good': 0.4512664720342885,\n",
       "  'not very': -1.0,\n",
       "  'very good': 0.5062201542746273,\n",
       "  'not very good': -0.9546976914357941},\n",
       " 'lime': {'good': -1.0,\n",
       "  'very': -0.9373920571357474,\n",
       "  'not': -0.4389411158898226},\n",
       " 'shap': {'not ': -1.0,\n",
       "  'very ': -0.0067576939967995955,\n",
       "  'good': 0.029314218115232517}}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_normed = {}\n",
    "for k in scores_all:\n",
    "    vmax = max(np.abs(list(scores_all[k].values())))\n",
    "    scores_normed[k] = {key: value / vmax for key, value in scores_all[k].items()}\n",
    "scores_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.color_palette('vlag_r', as_cmap=True) #20, 220, as_cmap=True, center='light')\n",
    "import matplotlib\n",
    "\n",
    "norm = matplotlib.colors.Normalize(vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embgam\n",
      "\t not bad #cdd3df\n",
      "\t not #e8cac8\n",
      "\t very #faf3f2\n",
      "\t good #a5b5ce\n",
      "\t not very #a9373b\n",
      "\t very good #9aadca\n",
      "\t not very good #ac3f42\n",
      "lime\n",
      "\t good #a9373b\n",
      "\t very #af4446\n",
      "\t not #d8a3a0\n",
      "shap\n",
      "\t not  #a9373b\n",
      "\t very  #faf5f4\n",
      "\t good #f9f5f5\n"
     ]
    }
   ],
   "source": [
    "for method in scores_normed:\n",
    "    print(method)\n",
    "    for k in scores_normed[method]:\n",
    "        print('\\t', k, matplotlib.colors.rgb2hex(cmap(norm(scores_normed[method][k]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQB2bGFnX3IgY29sb3JtYXDXuiQbAAAAG3RFWHREZXNjcmlwdGlvbgB2bGFnX3IgY29sb3JtYXCeLTz/AAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My42LjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmfhqHMCAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ88O7CUAAAIbSURBVHic7dbBUoMwGIXRpA/lwif2JQUXhTpN+jfo9p6zQdJAAsw4X//6+Nxba63fbu1+7O3+R2+vxvsx3orxc/50/eN8uH4Y7/24fjgv9zXuZ1ynj/sc739t31fvv17v/fzL6xf3vb7OYp+L9X/P//f8630W6033Gb9L8R2v3n/cT3H/+n0t1lu+h4vvs3re83mq4+k439tr+/HDPp4/xvfjfH8a37bn8W38/Ryv5m3P57/jrRgv5j/WacX4uP4wb1vsf5pXrHO+r2mfrXj+Yp3p/u3pOZbzyv283sc8fp4P99uqedV7aYt5w/j0/dr7+RfH19cN86fvXMybju/X/+vxe9rXON5fzvsujsd/DwAgiQAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAAC/QC+rDTWCv11VgAAAABJRU5ErkJggg==",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>vlag_r</strong> </div><div class=\"cmap\"><img alt=\"vlag_r colormap\" title=\"vlag_r\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFXRFWHRUaXRsZQB2bGFnX3IgY29sb3JtYXDXuiQbAAAAG3RFWHREZXNjcmlwdGlvbgB2bGFnX3IgY29sb3JtYXCeLTz/AAAAMHRFWHRBdXRob3IATWF0cGxvdGxpYiB2My42LjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmfhqHMCAAAAMnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHYzLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZ88O7CUAAAIbSURBVHic7dbBUoMwGIXRpA/lwif2JQUXhTpN+jfo9p6zQdJAAsw4X//6+Nxba63fbu1+7O3+R2+vxvsx3orxc/50/eN8uH4Y7/24fjgv9zXuZ1ynj/sc739t31fvv17v/fzL6xf3vb7OYp+L9X/P//f8630W6033Gb9L8R2v3n/cT3H/+n0t1lu+h4vvs3re83mq4+k439tr+/HDPp4/xvfjfH8a37bn8W38/Ryv5m3P57/jrRgv5j/WacX4uP4wb1vsf5pXrHO+r2mfrXj+Yp3p/u3pOZbzyv283sc8fp4P99uqedV7aYt5w/j0/dr7+RfH19cN86fvXMybju/X/+vxe9rXON5fzvsujsd/DwAgiQAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAACCQAACCQAACCQAACAQAIAAAIJAAAIJAAAIJAAAIBAAgAAAgkAAAgkAAAgkAAAgEACAAAC/QC+rDTWCv11VgAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#a9373bff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #a9373bff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#2369bdff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #2369bdff;\"></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x7f27495d02b0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7649441118665306, 0.3396246444984717, 0.23152090062227623, 1.0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmap(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
