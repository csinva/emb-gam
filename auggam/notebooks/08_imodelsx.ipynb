{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import ClassifierMixin, RegressorMixin\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import joblib\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "sys.path.append('../results')\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import auggam.config\n",
    "RESULTS_DIR = join(auggam.config.results_dir, '7gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [fname for fname in os.listdir(RESULTS_DIR)] # if fname.startswith('instructor')]\n",
    "# accs = pd.read_pickle('../results/instructor_accs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames_acc = [fname for fname in fnames if 'acc_' in fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>model</th>\n",
       "      <th>dset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800188</td>\n",
       "      <td>instructor</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496000</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.819887</td>\n",
       "      <td>llama_7b</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.709500</td>\n",
       "      <td>instructor</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879079</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>ag_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.760526</td>\n",
       "      <td>instructor</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.874000</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>trec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.761726</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.648500</td>\n",
       "      <td>linear_finetune</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.863158</td>\n",
       "      <td>linear_finetune</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.887763</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>ag_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.680500</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.816514</td>\n",
       "      <td>llama_7b</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.847477</td>\n",
       "      <td>instructor</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.815197</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.956829</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>dbpedia_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.860000</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.759649</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.749531</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.813321</td>\n",
       "      <td>linear_finetune</td>\n",
       "      <td>rotten_tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.983714</td>\n",
       "      <td>linear_finetune</td>\n",
       "      <td>dbpedia_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.944000</td>\n",
       "      <td>bert-finetuned</td>\n",
       "      <td>trec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.821053</td>\n",
       "      <td>llama_7b</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.853211</td>\n",
       "      <td>linear_finetune</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.787844</td>\n",
       "      <td>gpt2-xl</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.719298</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.733500</td>\n",
       "      <td>llama_7b</td>\n",
       "      <td>emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>financial_phrasebank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.861053</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>ag_news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.890000</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>trec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.714450</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.810780</td>\n",
       "      <td>tfidfvectorizer</td>\n",
       "      <td>sst2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.906447</td>\n",
       "      <td>bert-finetuned</td>\n",
       "      <td>ag_news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc              model                  dset\n",
       "0   0.800188         instructor       rotten_tomatoes\n",
       "1   0.496000               gpt2               emotion\n",
       "2   0.819887           llama_7b       rotten_tomatoes\n",
       "3   0.709500         instructor               emotion\n",
       "4   0.879079    tfidfvectorizer               ag_news\n",
       "5   0.760526         instructor  financial_phrasebank\n",
       "6   0.874000    tfidfvectorizer                  trec\n",
       "7   0.761726               gpt2       rotten_tomatoes\n",
       "8   0.648500    linear_finetune               emotion\n",
       "9   0.863158    linear_finetune  financial_phrasebank\n",
       "10  0.887763  bert-base-uncased               ag_news\n",
       "11  0.680500            gpt2-xl               emotion\n",
       "12  0.816514           llama_7b                  sst2\n",
       "13  0.847477         instructor                  sst2\n",
       "14  0.815197            gpt2-xl       rotten_tomatoes\n",
       "15  0.956829    tfidfvectorizer            dbpedia_14\n",
       "16  0.860000    tfidfvectorizer               emotion\n",
       "17  0.759649            gpt2-xl  financial_phrasebank\n",
       "18  0.749531    tfidfvectorizer       rotten_tomatoes\n",
       "19  0.813321    linear_finetune       rotten_tomatoes\n",
       "20  0.983714    linear_finetune            dbpedia_14\n",
       "21  0.944000     bert-finetuned                  trec\n",
       "22  0.821053           llama_7b  financial_phrasebank\n",
       "23  0.853211    linear_finetune                  sst2\n",
       "24  0.787844            gpt2-xl                  sst2\n",
       "25  0.719298               gpt2  financial_phrasebank\n",
       "26  0.733500           llama_7b               emotion\n",
       "27  0.833333    tfidfvectorizer  financial_phrasebank\n",
       "28  0.861053               gpt2               ag_news\n",
       "29  0.890000  bert-base-uncased                  trec\n",
       "30  0.714450               gpt2                  sst2\n",
       "31  0.810780    tfidfvectorizer                  sst2\n",
       "32  0.906447     bert-finetuned               ag_news"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = defaultdict(list)\n",
    "def rename_bert_models(s):\n",
    "    if 'bert' in s and not s == 'bert-base-uncased':\n",
    "        return 'bert-finetuned'\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "for fname in fnames_acc:\n",
    "    # print(fname)\n",
    "    acc = joblib.load(join(RESULTS_DIR, fname))\n",
    "    # print(acc)\n",
    "    df['acc'].append(acc['acc_val'])\n",
    "    # print(fname.split('_acc_'))\n",
    "    df['model'].append(fname.split('_acc_')[0])\n",
    "    df['dset'].append(fname.split('_acc_')[1].replace('_imodelsx.pkl', ''))\n",
    "# joblib.load(join('../results', fnames_acc[0]))\n",
    "df = pd.DataFrame(df)\n",
    "df['model'] = df['model'].apply(rename_bert_models)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dset</th>\n",
       "      <th>ag_news</th>\n",
       "      <th>dbpedia_14</th>\n",
       "      <th>emotion</th>\n",
       "      <th>financial_phrasebank</th>\n",
       "      <th>rotten_tomatoes</th>\n",
       "      <th>sst2</th>\n",
       "      <th>trec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bert-base-uncased</th>\n",
       "      <td>0.887763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-finetuned</th>\n",
       "      <td>0.906447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.861053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.761726</td>\n",
       "      <td>0.714450</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2-xl</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.759649</td>\n",
       "      <td>0.815197</td>\n",
       "      <td>0.787844</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instructor</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7095</td>\n",
       "      <td>0.760526</td>\n",
       "      <td>0.800188</td>\n",
       "      <td>0.847477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_finetune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983714</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.863158</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>0.853211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.819887</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidfvectorizer</th>\n",
       "      <td>0.879079</td>\n",
       "      <td>0.956829</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.749531</td>\n",
       "      <td>0.810780</td>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dset                ag_news  dbpedia_14  emotion  financial_phrasebank   \n",
       "model                                                                    \n",
       "bert-base-uncased  0.887763         NaN      NaN                   NaN  \\\n",
       "bert-finetuned     0.906447         NaN      NaN                   NaN   \n",
       "gpt2               0.861053         NaN   0.4960              0.719298   \n",
       "gpt2-xl                 NaN         NaN   0.6805              0.759649   \n",
       "instructor              NaN         NaN   0.7095              0.760526   \n",
       "linear_finetune         NaN    0.983714   0.6485              0.863158   \n",
       "llama_7b                NaN         NaN   0.7335              0.821053   \n",
       "tfidfvectorizer    0.879079    0.956829   0.8600              0.833333   \n",
       "\n",
       "dset               rotten_tomatoes      sst2   trec  \n",
       "model                                                \n",
       "bert-base-uncased              NaN       NaN  0.890  \n",
       "bert-finetuned                 NaN       NaN  0.944  \n",
       "gpt2                      0.761726  0.714450    NaN  \n",
       "gpt2-xl                   0.815197  0.787844    NaN  \n",
       "instructor                0.800188  0.847477    NaN  \n",
       "linear_finetune           0.813321  0.853211    NaN  \n",
       "llama_7b                  0.819887  0.816514    NaN  \n",
       "tfidfvectorizer           0.749531  0.810780  0.874  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot(index='model', columns='dset', values='acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
