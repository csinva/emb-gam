{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import joblib\n",
    "import auggam.config\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "sys.path.append('../results')\n",
    "pd.set_option('display.max_rows', None)\n",
    "RESULTS_DIR = join(auggam.config.results_dir, '7gram')\n",
    "\n",
    "fnames = [fname for fname in os.listdir(RESULTS_DIR)] # if fname.startswith('instructor')]\n",
    "# accs = pd.read_pickle('../results/instructor_accs.pkl')\n",
    "fnames_acc = [fname for fname in fnames if 'acc_' in fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = defaultdict(list)\n",
    "\n",
    "\n",
    "def rename_models(s):\n",
    "    if \"bert\" in s.lower() and not s == \"bert-base-uncased\":\n",
    "        return \"BERT finetuned\"\n",
    "    elif \"instructor\" in s.lower():\n",
    "        return \"Instructor\"\n",
    "    elif s == 'gpt2':\n",
    "        return 'GPT-2 (124M)'\n",
    "    elif s == 'gpt2-xl':\n",
    "        return 'GPT-2 (1.5B)'\n",
    "    elif s == 'llama_7b':\n",
    "        return 'LlaMA (7B)'\n",
    "    elif s == 'bert-base-uncased':\n",
    "        return 'BERT'\n",
    "    elif s == 'linear_finetune':\n",
    "        return 'BERT single-layer finetuned'\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "\n",
    "for fname in fnames_acc:\n",
    "    # print(fname)\n",
    "    acc = joblib.load(join(RESULTS_DIR, fname))\n",
    "    # print(acc)\n",
    "    df[\"acc\"].append(acc[\"acc_val\"])\n",
    "    # print(fname.split('_acc_'))\n",
    "    df[\"model\"].append(fname.split(\"_acc_\")[0])\n",
    "    df[\"dset\"].append(fname.split(\"_acc_\")[1].replace(\"_imodelsx.pkl\", \"\"))\n",
    "    df[\"fname\"].append(fname)\n",
    "    df[\"tokenizer_simplified\"].append(\"tokenizer\" in fname)\n",
    "# joblib.load(join('../results', fnames_acc[0]))\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# remove one redundant run\n",
    "df = df[~((df.dset == \"financial_phrasebank\") & (df.model == \"instructor\"))]\n",
    "\n",
    "\n",
    "df[\"model\"] = df[\"model\"].apply(rename_models)\n",
    "df[\"dset\"] = df[\"dset\"].apply(lambda x: x.split(\"_tokenizer\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    df.pivot(index=['tokenizer_simplified', 'model'], columns='dset', values='acc').round(3)\n",
    ")\n",
    "d.style.format(precision=3).background_gradient(cmap='Blues', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((100 * d[[\"financial_phrasebank\", \"rotten_tomatoes\", \"sst2\", \"emotion\", ]]).style.format(precision=1).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((100 * d[[\"ag_news\", \"dbpedia_14\", \"trec\"]]).style.format(precision=1).to_latex(hrules=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((100 * d[[\"ag_news\", \"dbpedia_14\", \"trec\"]]).mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".embgam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
