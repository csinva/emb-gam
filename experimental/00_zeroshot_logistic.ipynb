{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fa105ccc8c4bd59f07f60bd2ba0ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c52810f5234f8db78ca1277b92a119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append('../experiments/')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from os.path import join\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from imodelsx import AugLinearClassifier\n",
    "from imodelsx.zeroshot.zeroshotlinear import ZeroShotLinearClassifier\n",
    "\n",
    "# load dset\n",
    "dset = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "dset = dset.select(np.random.choice(len(dset), size=100, replace=False))\n",
    "\n",
    "dset_val = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "dset_val = dset_val.select(np.random.choice(\n",
    "    len(dset_val), size=100, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ZeroShotLinearClassifier(\n",
    "    checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes',\n",
    "    ngrams=2,\n",
    "    all_ngrams=True,  # also use lower-order ngrams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing model...\n",
      "calculating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training linear model...\n",
      "caching linear coefs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:26<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAfter caching, coefs_dict_ len 2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAfter caching, coefs_dict_ len 5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m.fit(dset['text'], dset['label'])\n",
    "m.cache_linear_coefs(dset_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train 0.99\n",
      "acc_val 0.77\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(dset['text'])\n",
    "print('acc_train', np.mean(preds == dset['label']))\n",
    "preds_proba = m.predict_proba(dset['text'])\n",
    "preds = m.predict(dset_val['text'])\n",
    "print('acc_val', np.mean(preds == dset_val['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing model...\n",
      "calculating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:40<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training linear model...\n",
      "caching linear coefs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:23<00:00,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAfter caching, coefs_dict_ len 2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AugLinearClassifier(all_ngrams=True,\n",
       "                    checkpoint=&#x27;textattack/distilbert-base-uncased-rotten-tomatoes&#x27;,\n",
       "                    tokenizer_ngrams=&lt;spacy.tokenizer.Tokenizer object at 0x7f3016097d00&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AugLinearClassifier</label><div class=\"sk-toggleable__content\"><pre>AugLinearClassifier(all_ngrams=True,\n",
       "                    checkpoint=&#x27;textattack/distilbert-base-uncased-rotten-tomatoes&#x27;,\n",
       "                    tokenizer_ngrams=&lt;spacy.tokenizer.Tokenizer object at 0x7f3016097d00&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AugLinearClassifier(all_ngrams=True,\n",
       "                    checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes',\n",
       "                    tokenizer_ngrams=<spacy.tokenizer.Tokenizer object at 0x7f3016097d00>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = AugLinearClassifier(\n",
    "    checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes',\n",
    "    ngrams=2,\n",
    "    all_ngrams=True,  # also use lower-order ngrams\n",
    ")\n",
    "m.fit(dset['text'], dset['label'])\n",
    "m.cache_linear_coefs(dset_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train 0.99\n",
      "acc_val 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/imodelsx/auglinear/auglinear.py:397: UserWarning: Saw an unseen ungram 2541 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds = m.predict(dset['text'])\n",
    "print('acc_train', np.mean(preds == dset['label']))\n",
    "preds_proba = m.predict_proba(dset['text'])\n",
    "preds = m.predict(dset_val['text'])\n",
    "print('acc_val', np.mean(preds == dset_val['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ngram coefficients:  2654\n",
      "Most positive ngrams\n",
      "\t a compelling 1.01\n",
      "\t warm and 0.95\n",
      "\t stunning . 0.94\n",
      "\t exquisite acting 0.92\n",
      "\t compelling 0.91\n",
      "\t tremendous performance 0.91\n",
      "\t a tremendous 0.86\n",
      "\t enjoyable , 0.85\n",
      "Most negative ngrams\n",
      "\t idiotic and -0.69\n",
      "\t is idiotic -0.66\n",
      "\t tiresome . -0.63\n",
      "\t condescending and -0.6\n",
      "\t generic , -0.58\n",
      "\t gags . -0.56\n",
      "\t , rather -0.55\n",
      "\t pretentious and -0.55\n"
     ]
    }
   ],
   "source": [
    "print('Total ngram coefficients: ', len(m.coefs_dict_))\n",
    "print('Most positive ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1], reverse=True)[:8]:\n",
    "    print('\\t', k, round(v, 2))\n",
    "print('Most negative ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1])[:8]:\n",
    "    print('\\t', k, round(v, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
