{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-07 14:53:08,905] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/thinc/compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "/home/chansingh/imodelsx/.venv/lib/python3.11/site-packages/thinc/compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9382a55493b944cfb480c4a758e5d32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253d4851154846e79150ba5e64e1effc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append('../experiments/')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from os.path import join\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from imodelsx import AugLinearClassifier\n",
    "\n",
    "# load dset\n",
    "dset = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "dset = dset.select(np.random.choice(len(dset), size=100, replace=False))\n",
    "\n",
    "dset_val = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "dset_val = dset_val.select(np.random.choice(\n",
    "    len(dset_val), size=100, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing model...\n",
      "setting up zero-shot linear model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAfter caching, coefs_dict_ len 1801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = AugLinearClassifier(\n",
    "    checkpoint='bert-base-uncased',\n",
    "    # checkpoint='textattack/distilbert-base-uncased-rotten-tomatoes', # much better performance but cheating\n",
    "    ngrams=2,\n",
    "    all_ngrams=True,  # also use lower-order ngrams\n",
    "    zeroshot_class_dict={0: ['negative', 'boring'],\n",
    "                         1: ['positive', 'great']},\n",
    "    prune_stopwords=True,\n",
    ")\n",
    "m.fit(None, [0, 1])\n",
    "m.cache_linear_coefs(dset_val['text'], renormalize_embs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_val 0.76\n",
      "roc 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chansingh/imodelsx/imodelsx/auglinear/auglinear.py:419: UserWarning: Saw an unseen ungram 1822 times. For better performance, call cache_linear_coefs on the test dataset before calling predict.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = m.predict(dset_val['text'])\n",
    "# m._predict_cached(dset_val['text'], warn=False)\n",
    "preds_proba = m.predict_proba(dset['text'])\n",
    "print('acc_val', np.mean(preds == dset_val['label']))\n",
    "print('roc', roc_auc_score(dset_val['label'], preds_proba[:, 1]).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.4904089 , 15.62479973, 20.11520863])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m._predict_cached(['fun', 'great', 'great positive nice fun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ngram coefficients:  1805\n",
      "Most positive ngrams\n",
      "\t great 10.0\n",
      "\t good 8.63\n",
      "\t enthusiastic 8.57\n",
      "\t good overall 7.41\n",
      "\t big 6.79\n",
      "\t splendid 6.66\n",
      "\t convincing 6.63\n",
      "\t mean 6.37\n",
      "\t bravo 6.19\n",
      "\t man 6.17\n",
      "\t obsessed 6.16\n",
      "\t missed 6.14\n",
      "\t guys 6.08\n",
      "\t pretty 6.07\n",
      "\t sure 6.04\n",
      "\t scary 6.04\n",
      "\t spirited 6.02\n",
      "\t effectiveness 6.0\n",
      "\t hilarious 6.0\n",
      "\t fun 5.99\n",
      "\t predictable 5.98\n",
      "\t obvious 5.88\n",
      "\t neat 5.78\n",
      "\t foul 5.71\n",
      "\t bigger 5.69\n",
      "\t quirky 5.67\n",
      "\t right 5.64\n",
      "\t spy 5.64\n",
      "\t rude 5.62\n",
      "\t stuff 5.62\n",
      "Most negative ngrams\n",
      "\t sci -7.72\n",
      "\t meditation ethereal -7.19\n",
      "\t parachutes onto -6.97\n",
      "\t parachutes -6.86\n",
      "\t moves away -6.77\n",
      "\t cardellini -6.39\n",
      "\t benjamins -6.34\n",
      "\t representation every -6.27\n",
      "\t society -6.25\n",
      "\t arm's -6.14\n",
      "\t preserves tosca -5.91\n",
      "\t single stroke -5.87\n",
      "\t atmospheric meditation -5.86\n",
      "\t onto moving -5.75\n",
      "\t lillard cardellini -5.74\n",
      "\t deliberate gait -5.66\n",
      "\t life arm's -5.65\n",
      "\t pretensions -5.51\n",
      "\t signposts discovering -5.33\n",
      "\t 've seen -5.26\n",
      "\t pena taquilla -5.19\n",
      "\t cobbled together -5.15\n",
      "\t sensación inconformidad -5.12\n",
      "\t century footnotes -5.07\n",
      "\t hippie turned -5.03\n",
      "\t overwrought existentialism -5.01\n",
      "\t frank parachutes -4.99\n",
      "\t signposts -4.93\n",
      "\t ever always -4.9\n",
      "\t jacquot -4.9\n"
     ]
    }
   ],
   "source": [
    "print('Total ngram coefficients: ', len(m.coefs_dict_))\n",
    "print('Most positive ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1], reverse=True)[:30]:\n",
    "    print('\\t', k, round(v, 2))\n",
    "print('Most negative ngrams')\n",
    "for k, v in sorted(m.coefs_dict_.items(), key=lambda item: item[1])[:30]:\n",
    "    print('\\t', k, round(v, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
