{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes data from https://github.com/HuthLab/deep-fMRI-dataset. To set up, see instructions in the `deep-fMRI-dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datasets\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from encoding.ridge_utils.SemanticModel import SemanticModel\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from encoding.feature_spaces import em_data_dir, data_dir, results_dir\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes (/home/chansingh/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777677675c404a7597857e467db2f54d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes (/home/chansingh/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf33b5593334f42a972e629ead9e667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes 8530 1066\n"
     ]
    }
   ],
   "source": [
    "dset = datasets.load_dataset('rotten_tomatoes')['train']\n",
    "# dset = dset.select(np.random.choice(len(dset), size=300, replace=False))\n",
    "X = dset['text']\n",
    "y = dset['label']\n",
    "\n",
    "dset_test = datasets.load_dataset('rotten_tomatoes')['validation']\n",
    "# dset_test = dset_test.select(np.random.choice(len(dset_test), size=300, replace=False))\n",
    "X_test = dset_test['text']\n",
    "y_test = dset_test['label']\n",
    "print('shapes', len(X), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(X: List[str], save_location) -> np.ndarray:\n",
    "    eng1000 = SemanticModel.load(join(em_data_dir, 'english1000sm.hf5'))\n",
    "    # extract features\n",
    "    X = [\n",
    "        [word.encode('utf-8') for word in sentence.split(' ')]\n",
    "        for sentence in X\n",
    "    ]\n",
    "    feats = eng1000.project_stims(X)\n",
    "    return feats\n",
    "\n",
    "def get_embs_fmri(X: List[str], save_location, perc_threshold=98) -> np.ndarray:\n",
    "    feats = get_vecs(X, save_location)\n",
    "    weights_npz = np.load(join(save_location, 'weights.npz'))\n",
    "    corrs_val = np.load(join(save_location, 'corrs.npz'))['arr_0']\n",
    "    \n",
    "    weights = weights_npz['arr_0']\n",
    "    N_DELAYS = 4\n",
    "    # pretty sure this is right, but might be switched...\n",
    "    weights = weights.reshape(N_DELAYS, -1, feats.shape[-1]) \n",
    "    # delays for coefs are not stored next to each other!! (see cell 25 file:///Users/chandan/Downloads/speechmodeltutorial-master/SpeechModelTutorial%20-%20Pre-run.html)\n",
    "    # weights = weights.reshape(-1, N_DELAYS, feats.shape[-1]) \n",
    "    weights = weights.mean(axis=0).squeeze() # mean over delays dimension...\n",
    "    embs = feats @ weights.T\n",
    "\n",
    "    # subselect repr\n",
    "    perc = np.percentile(corrs_val, perc_threshold)\n",
    "    idxs = (corrs_val > perc)\n",
    "    # print('emb dim', idxs.sum(), 'val corr cutoff', perc)\n",
    "    embs = embs[:, idxs]\n",
    "\n",
    "    return embs\n",
    "\n",
    "def get_bow_vecs(X: List[str], X_test: List[str]):\n",
    "    trans = CountVectorizer().fit(X).transform\n",
    "    return trans(X).todense(), trans(X_test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "perc_threshold_fmri = 98\n",
    "save_location = join(results_dir, 'eng1000', 'UTS03')\n",
    "r = defaultdict(list)\n",
    "for k in ['eng1000fmri']: # ['eng1000vecs', 'eng1000fmri', 'bow']:\n",
    "    if k == 'eng1000vecs':\n",
    "        feats_train = get_vecs(X, save_location)\n",
    "        feats_test = get_vecs(X_test, save_location)\n",
    "    elif k == 'eng1000fmri':\n",
    "        feats_train = get_embs_fmri(X, save_location, perc_threshold=perc_threshold_fmri)\n",
    "        feats_test = get_embs_fmri(X_test, save_location, perc_threshold=perc_threshold_fmri) \n",
    "    elif k == 'bow':\n",
    "        feats_train, feats_test = get_bow_vecs(X, X_test)\n",
    "\n",
    "    m = LogisticRegressionCV(random_state=seed)\n",
    "    m.fit(feats_train, y)\n",
    "    r['feats'].append(k)\n",
    "    r['acc'].append(m.score(feats_test, y_test))\n",
    "    r['feats_dim'].append(feats_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>feats_dim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feats</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eng1000fmri</th>\n",
       "      <td>0.733583</td>\n",
       "      <td>4778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  acc  feats_dim\n",
       "feats                           \n",
       "eng1000fmri  0.733583       4778"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(r).set_index('feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
